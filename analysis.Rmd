## Practical Machine Learning
### Assignment
-- Author: hpschu --

```{r}
library(caret)
library(doMC)
cores <- parallel::detectCores()
registerDoMC(cores)
```


```{r}
# Download data:
if (!file.exists('training.csv')) download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv', method = 'curl', destfile = 'training.csv')
if (!file.exists('testing.csv')) download.file('https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv', method = 'curl', destfile = 'testing.csv')

# Set Seed
set.seed(1234)

data <- as.data.frame(read.table('training.csv', sep=",", header = T))
#####################################################################
# TESTING!!!: #######################################################
data <- data[createDataPartition(data$classe, p = 0.3, list = F),] ##
#####################################################################

test_set <- as.data.frame(read.table('testing.csv', sep=",", header = T))

```

The X-variable seems to work as an index variable and is thus removed from the training- and test sets. Additionally, max_roll_belt, max_pitch_belt, min_roll_belt, min_pitch_belt, amplitude_roll_belt, amplitude_pitch_belt, and var_total_accel_belt had a vast amount of missing variables. These variables were also removed. Furthermore, time stamps and near zero variance variables are removed.

Names for the test subjects were recoded into numeric categorical variables.

```{r}


y <- data$classe
data <- data[,-ncol(data)]

# Remove first set of variables and x variable
removeCol <- c(1, 3, 4, 5, 6, 7, 10:16)

nearZeroVar(data, saveMetrics = T)
nearZeroVariables <- nearZeroVar(data)

removeCol <- unique(c(removeCol, nearZeroVariables))

Nas <- apply(data, MARGIN = 2, function(x){if(TRUE %in% unique(is.na(x))) return(TRUE) else return(FALSE)})

removeCol <- unique(c(removeCol, which(colnames(data) %in% colnames(data)[Nas])))

data <- data[,-removeCol]

# Recode users in alphabetical order from 1 to nth user

users <- sort(unique(data$user_name))
user_name <- data$user_name
tempusers <- vector()
for (i in 1:length(users)){
  tempusers[user_name == users[i]] <- i
}

data$user_name <- as.factor(tempusers)

```

After cleaning, 51 variables were left for the prediction. Next, the data was divided into training and testing sets. PCA with Z-normalization was used for the data to reduce dimensionality.

```{r}
trainInd <- createDataPartition(y, p = 0.7, list=F)
data <- cbind(data, y)

training <- data[trainInd,]
testing <- data[-trainInd,]

# Fit control settings, set cross validation to 10-fold repeated cv with 3 repeats.

model <- train(y ~ ., method = 'rf', preProcess = c('center', 'scale', 'pca'), data = training, trainControl = trainControl(method = 'repeatedcv', number = 10, repeats = 3))

```